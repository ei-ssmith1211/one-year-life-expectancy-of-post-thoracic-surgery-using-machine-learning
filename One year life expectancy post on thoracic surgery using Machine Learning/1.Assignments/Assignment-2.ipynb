{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9104081-a4cc-4e84-8b71-ad017c57fb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ebe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\cc\\Downloads\\ThoracicSurgery.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22edb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b731b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "live=df[df['Death_1yr']==0]\n",
    "death=df[df['Death_1yr']==1]\n",
    "\n",
    "cond=['FVC', 'FEV1', 'Performance', 'Pain', 'Haemoptysis',\n",
    "       'Dyspnoea', 'Cough', 'Weakness', 'Tumor_Size', 'Diabetes_Mellitus',\n",
    "       'MI_6mo', 'PAD', 'Smoking', 'Asthma', 'Age']\n",
    "l=[np.mean(live[c]) for c in cond]\n",
    "d=[np.mean(death[c]) for c in cond]\n",
    "\n",
    "ld=pd.DataFrame(data={'Attribute':cond,'Live 1yr Mean':l,'Death 1yr Mean':d})\n",
    "ld=ld.set_index('Attribute')\n",
    "\n",
    "print('Death: {:d}'.format(len(death),len(live)))\n",
    "print('Live: {:d}'.format(len(live),len(death)))\n",
    "print(\"1 year death: {:.2f}% out of 454 patients\".format(np.mean(df.Death_1yr)*100))\n",
    "ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37970368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW MANY PATIENTS DIED IN 1 YEAR\n",
    "#PERCENTAGE DIFFERENCE IN MEANS OF LIVE VS DEATH PATIENTS\n",
    "d=np.array(d)\n",
    "l=np.array(l)\n",
    "p_diff=(d-l)/l*100\n",
    "\n",
    "fig,axes=plt.subplots(2,1,figsize=(12,18))\n",
    "axes[0].bar(cond,p_diff)\n",
    "axes[0].set_title('Mean Difference % between Dead and Live 1yr',fontsize=18)\n",
    "axes[0].set_xticks(cond)\n",
    "axes[0].set_xticklabels(cond,rotation=90)\n",
    "axes[0].set_ylabel('Percent',fontsize=13)\n",
    "\n",
    "#COUNT PLOTS OF TRUE/FALSE CONDITION COLUMNS\n",
    "tf_col=['Pain','Haemoptysis','Dyspnoea','Cough','Weakness','Diabetes_Mellitus','MI_6mo','PAD','Smoking','Asthma']\n",
    "tf_sum=[df[col].sum()/454 for col in tf_col]\n",
    "\n",
    "axes[1].bar(tf_col,tf_sum)\n",
    "axes[1].set_xticks(tf_col)\n",
    "axes[1].set_xticklabels(tf_col,rotation=90)\n",
    "axes[1].set_ylabel('Proportion of Total Patients',fontsize=13)\n",
    "axes[1].set_title('Proportion of Patient Conditions before Surgery',fontsize=18)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Data(Diagnosis,Tumor_Size,Performance)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "sns.countplot(x='Diagnosis', hue='Death_1yr', data=df, palette='Blues_d', ax=axes[0])\n",
    "axes[0].set_title('Diagnosis')\n",
    "\n",
    "sns.countplot(x='Tumor_Size', hue='Death_1yr', data=df, palette='Blues_d', ax=axes[1])\n",
    "axes[1].set_title('Tumor_Size')\n",
    "\n",
    "sns.countplot(x='Performance', hue='Death_1yr', data=df, palette='Blues_d', ax=axes[2])\n",
    "axes[2].set_title('Performance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a743ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_sample(data1,data2):\n",
    "    data=np.concatenate((data1,data2))\n",
    "    permuted_data=np.random.permutation(data)\n",
    "    \n",
    "    perm_sample_1=permuted_data[:len(data1)]\n",
    "    perm_sample_2=permuted_data[len(data2):]\n",
    "    \n",
    "    return perm_sample_1,perm_sample_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition=['FVC', 'FEV1', 'Performance', 'Pain', 'Haemoptysis',\n",
    "       'Dyspnoea', 'Cough', 'Weakness', 'Tumor_Size', 'Diabetes_Mellitus',\n",
    "       'MI_6mo', 'PAD', 'Smoking', 'Asthma', 'Age']\n",
    "import numpy as np\n",
    "\n",
    "def diff_of_means(data1, data2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "    return np.mean(data1) - np.mean(data2)\n",
    "\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "    data = np.concatenate((data1, data2))\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "def draw_perm_reps(data1, data2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "    perm_replicates = np.empty(size)  # Initialize perm_replicates as an empty array of size 'size'\n",
    "    for i in range(size):\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data1, data2)\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "    return perm_replicates\n",
    "\n",
    "# Assuming 'death' and 'live' are pandas DataFrames and 'condition' is a list of columns\n",
    "for c in condition:\n",
    "    empirical_diff_means = diff_of_means(death[c], live[c])\n",
    "    perm_replicates = draw_perm_reps(death[c], live[c], diff_of_means, size=10000)\n",
    "    if empirical_diff_means > 0:\n",
    "        p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "    else:\n",
    "        p = np.sum(perm_replicates <= empirical_diff_means) / len(perm_replicates)\n",
    "    print(f\"p-value for {c}: {p}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff646e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition=['FVC', 'FEV1', 'Performance', 'Pain', 'Haemoptysis',\n",
    "       'Dyspnoea', 'Cough', 'Weakness', 'Tumor_Size', 'Diabetes_Mellitus',\n",
    "       'MI_6mo', 'PAD', 'Smoking', 'Asthma', 'Age']\n",
    "p_val=[]\n",
    "for c in condition:\n",
    "    empirical_diff_means=diff_of_means(death[c],live[c])\n",
    "    perm_replicates=draw_perm_reps(death[c],live[c],diff_of_means,size=10000)\n",
    "    if empirical_diff_means>0:\n",
    "        p=np.sum(perm_replicates>= empirical_diff_means)/len(perm_replicates)\n",
    "        p_val.append(p)\n",
    "    else:\n",
    "        p=np.sum(perm_replicates <= empirical_diff_means)/len(perm_replicates)\n",
    "        p_val.append(p)\n",
    "print(list(zip(condition,p_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical data(Age,FVC,FEV1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and it contains columns 'FVC', 'FEV1', and 'Age'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Plot FVC vs FEV1\n",
    "axes[0].plot(df.FVC, df.FEV1, linestyle='none', marker='.')\n",
    "axes[0].set_xlabel('FVC', fontsize=13)\n",
    "axes[0].set_ylabel('FEV1', fontsize=13)\n",
    "axes[0].set_title('FVC vs FEV1', fontsize=16)\n",
    "\n",
    "# Plot Age vs FEV1 and Age vs FVC\n",
    "axes[1].plot(df.Age, df.FEV1, linestyle='none', marker='.', label='FEV1')\n",
    "axes[1].plot(df.Age, df.FVC, linestyle='none', marker='.', label='FVC')\n",
    "axes[1].set_xlabel('Age', fontsize=13)\n",
    "axes[1].set_ylabel('FEV1, FVC', fontsize=13)\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Age vs FEV1, FVC', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877afde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation coefficients for FVC and FEV1\n",
    "np.corrcoef(df.FVC,df.FEV1)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3aacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation coefficients for Age and FVC\n",
    "np.corrcoef(df.Age,df.FVC)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation coefficients for Age and FEV1\n",
    "np.corrcoef(df.Age,df.FEV1)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations of FVC,FEV1 and Age\n",
    "def ecdf(data):\n",
    "    n=len(data)\n",
    "    x=np.sort(data)\n",
    "    y=np.arange(1,n+1)/n\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECDF of FVC,FEV1,Age\n",
    "x_fvc,y_fvc=ecdf(df.FVC)\n",
    "x_fev1,y_fev1=ecdf(df.FEV1)\n",
    "x_age,y_age=ecdf(df.Age)\n",
    "\n",
    "fig,axes=plt.subplots(1,2,figsize=(13,5))\n",
    "axes[0].plot(x_fvc,y_fvc,marker='.',linestyle='none',label='FVC')\n",
    "axes[0].plot(x_fev1,y_fev1,marker='.',linestyle='none',label='FEV1')\n",
    "\n",
    "axes[0].set_xlabel('Numerical Value',fontsize=13)\n",
    "axes[0].set_ylabel('ECDF',fontsize=13)\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_title('ECDF of FVC & FEV1',fontsize=16)\n",
    "\n",
    "axes[1].plot(x_age,y_age,marker='.',linestyle='none',label='Age')\n",
    "axes[1].set_xlabel('Years Old',fontsize=13)\n",
    "axes[1].set_ylabel('ECDF',fontsize=13)\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].set_title('ECDF of Age',fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87582980",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:15].values\n",
    "y=df.iloc[:,15:16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd16332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of x_train {}'.format(x_train.shape))\n",
    "print('Shape of y_train {}'.format(y_train.shape))\n",
    "print('Shape of x_test {}'.format(x_test.shape))\n",
    "print('Shape of y_test {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8caf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standard scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix=df.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(correlation_matrix,annot=True,cmap='coolwarm',linewidths=0.5)\n",
    "plt.title('corelation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\cc\\Downloads\\ThoracicSurgery.csv')\n",
    "\n",
    "# Feature selection\n",
    "# Select features relevant for prediction\n",
    "features = ['FVC', 'FEV1', 'Performance', 'Pain', 'Haemoptysis', 'Dyspnoea',\n",
    "            'Cough', 'Weakness', 'Tumor_Size', 'Diabetes_Mellitus', 'MI_6mo',\n",
    "            'PAD', 'Smoking', 'Asthma', 'Age']\n",
    "target = 'Death_1yr'\n",
    "\n",
    "# Prepare the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "# Train and evaluate classifiers\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Classifier': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f'Classifier: {name}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "# Print summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\cc\\Downloads\\ThoracicSurgery.csv')\n",
    "\n",
    "# Feature selection\n",
    "features = ['FVC', 'FEV1', 'Performance', 'Pain', 'Haemoptysis', 'Dyspnoea',\n",
    "            'Cough', 'Weakness', 'Tumor_Size', 'Diabetes_Mellitus', 'MI_6mo',\n",
    "            'PAD', 'Smoking', 'Asthma', 'Age']\n",
    "target = 'Death_1yr'\n",
    "\n",
    "# Prepare the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning with more values\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Score: {grid_search.best_score_}')\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Save the model and scaler to pickle files\n",
    "with open('best_random_forest_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_rf, model_file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "# Make predictions with the best estimator\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the model and scaler from the pickle files\n",
    "with open('best_random_forest_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as scaler_file:\n",
    "    loaded_scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Example new data for prediction (replace with actual data)\n",
    "new_data = np.array([[2.88,2.16,1, 0, 0, 0, 1, 1, 4, 0, 0, 0, 1, 0, 60]])\n",
    "\n",
    "# Normalize the new data using the loaded scaler\n",
    "new_data_normalized = loaded_scaler.transform(new_data)\n",
    "\n",
    "# Make prediction with the loaded model\n",
    "new_prediction = loaded_model.predict(new_data_normalized)\n",
    "\n",
    "print(f'Prediction for new data: {new_prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([[2.44,0.96,2,0,1,0,1,1,1,0,0,0,1,0,73]])\n",
    "\n",
    "# Normalize the new data using the loaded scaler\n",
    "new_data_normalized = loaded_scaler.transform(new_data)\n",
    "\n",
    "# Make prediction with the loaded model\n",
    "new_prediction = loaded_model.predict(new_data_normalized)\n",
    "\n",
    "print(f'Prediction for new data: {new_prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5aab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c1214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c13796-b003-4e72-800d-0d23c2002d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7996a0d-bfc0-4646-ae6d-e123597b4f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d096429-9a48-45f6-b287-6551c3b4c6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17995a-470e-4fe6-b193-d24411545c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b4397-2966-4a8e-8099-84bfb968b63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a1561-d00f-4a11-9c23-1b01bc4bab32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955069b6-5964-4d5f-8a69-64012769b4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
